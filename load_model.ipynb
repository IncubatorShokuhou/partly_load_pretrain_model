{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-30 17:35:16--  https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\n",
      "正在解析主机 download.pytorch.org (download.pytorch.org)... 99.84.133.37, 99.84.133.87, 99.84.133.59, ...\n",
      "正在连接 download.pytorch.org (download.pytorch.org)|99.84.133.37|:443... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 200 OK\n",
      "长度： 178728960 (170M) [application/octet-stream]\n",
      "正在保存至: “./modeling/backbone/resnet101-5d3b4d8f.pth.1”\n",
      "\n",
      "resnet101-5d3b4d8f. 100%[===================>] 170.45M  12.0MB/s    用时 15s     \n",
      "\n",
      "2020-07-30 17:35:31 (11.6 MB/s) - 已保存 “./modeling/backbone/resnet101-5d3b4d8f.pth.1” [178728960/178728960])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#下载pretrained resnet101\n",
    "!wget https://download.pytorch.org/models/resnet101-5d3b4d8f.pth -P ./modeling/backbone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummaryX import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None, BatchNorm=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, \n",
    "                                dilation=dilation, padding=dilation, bias=False)\n",
    "        self.bn1 = BatchNorm(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None, BatchNorm=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = BatchNorm(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               dilation=dilation, padding=dilation, bias=False)\n",
    "        self.bn2 = BatchNorm(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = BatchNorm(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, output_stride, BatchNorm, model_trained, pretrained=True):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        blocks = [1, 2, 4]\n",
    "        if output_stride == 16:\n",
    "            strides = [1, 2, 2, 1]\n",
    "            dilations = [1, 1, 1, 2]\n",
    "        elif output_stride == 8:\n",
    "            strides = [1, 2, 1, 1]\n",
    "            dilations = [1, 1, 2, 4]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        # Modules\n",
    "        # 删除头部层\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "#         self.bn1 = BatchNorm(64)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=strides[0], dilation=dilations[0], BatchNorm=BatchNorm)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=strides[1], dilation=dilations[1], BatchNorm=BatchNorm)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=strides[2], dilation=dilations[2], BatchNorm=BatchNorm)\n",
    "        self.layer4 = self._make_MG_unit(block, 512, blocks=blocks, stride=strides[3], dilation=dilations[3], BatchNorm=BatchNorm)\n",
    "        # self.layer4 = self._make_layer(block, 512, layers[3], stride=strides[3], dilation=dilations[3], BatchNorm=BatchNorm)\n",
    "        self._init_weight()\n",
    "        \n",
    "        if pretrained:\n",
    "            self._load_pretrained_model(model_trained)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, BatchNorm=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                BatchNorm(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, dilation, downsample, BatchNorm))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation, BatchNorm=BatchNorm))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_MG_unit(self, block, planes, blocks, stride=1, dilation=1, BatchNorm=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                BatchNorm(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, dilation=blocks[0]*dilation,\n",
    "                            downsample=downsample, BatchNorm=BatchNorm))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, len(blocks)):\n",
    "            layers.append(block(self.inplanes, planes, stride=1,\n",
    "                                dilation=blocks[i]*dilation, BatchNorm=BatchNorm))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "#         x = self.conv1(input)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        low_level_feat = x\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x, low_level_feat\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            # elif isinstance(m, SynchronizedBatchNorm2d):\n",
    "            #     m.weight.data.fill_(1)\n",
    "            #     m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "    def _load_pretrained_model(self, model_trained):\n",
    "        # pretrain_dict = model_zoo.load_url('https://download.pytorch.org/models/resnet101-5d3b4d8f.pth')\n",
    "        pretrain_dict = torch.load(model_trained)\n",
    "        model_dict = {}\n",
    "        state_dict = self.state_dict()\n",
    "        for k, v in pretrain_dict.items():\n",
    "            if k in state_dict:\n",
    "                model_dict[k] = v\n",
    "        state_dict.update(model_dict)\n",
    "        self.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_head(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self._init_weight()\n",
    "        \n",
    "    def forward(self, x):\n",
    " \n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        return x\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "#             print(\"qq\",m)\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            # elif isinstance(m, SynchronizedBatchNorm2d):\n",
    "            #     m.weight.data.fill_(1)\n",
    "            #     m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet101(output_stride, BatchNorm, pretrained=True):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model_trained = 'modeling/backbone/resnet101-5d3b4d8f.pth'\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], output_stride, BatchNorm, model_trained, pretrained=pretrained)\n",
    "    return model\n",
    "\n",
    "def ResNet18(output_stride, BatchNorm, pretrained=True):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model_trained = 'modeling/backbone/resnet18-5c106cde.pth'\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_stride, BatchNorm, model_trained, pretrained=pretrained)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of head output torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 2048, 64, 64])\n",
      "torch.Size([1, 256, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "head = ResNet_head()   #单独把头部部分和下半部分拆分，下半部分读取预训练数据，上半部分自行初始化\n",
    "model = ResNet101(BatchNorm=nn.BatchNorm2d, pretrained=True, output_stride=8)\n",
    "\n",
    "input = torch.rand(1, 3, 512, 512)\n",
    "head_output = head(input)\n",
    "print(\"size of head output\",head_output.shape)\n",
    "output, low_level_feat = model(head_output)\n",
    "print(output.size())\n",
    "print(low_level_feat.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "                                             Kernel Shape        Output Shape  \\\n",
      "Layer                                                                           \n",
      "0_layer1.0.Conv2d_conv1                    [64, 64, 1, 1]   [1, 64, 128, 128]   \n",
      "1_layer1.0.BatchNorm2d_bn1                           [64]   [1, 64, 128, 128]   \n",
      "2_layer1.0.ReLU_relu                                    -   [1, 64, 128, 128]   \n",
      "3_layer1.0.Conv2d_conv2                    [64, 64, 3, 3]   [1, 64, 128, 128]   \n",
      "4_layer1.0.BatchNorm2d_bn2                           [64]   [1, 64, 128, 128]   \n",
      "5_layer1.0.ReLU_relu                                    -   [1, 64, 128, 128]   \n",
      "6_layer1.0.Conv2d_conv3                   [64, 256, 1, 1]  [1, 256, 128, 128]   \n",
      "7_layer1.0.BatchNorm2d_bn3                          [256]  [1, 256, 128, 128]   \n",
      "8_layer1.0.downsample.Conv2d_0            [64, 256, 1, 1]  [1, 256, 128, 128]   \n",
      "9_layer1.0.downsample.BatchNorm2d_1                 [256]  [1, 256, 128, 128]   \n",
      "10_layer1.0.ReLU_relu                                   -  [1, 256, 128, 128]   \n",
      "11_layer1.1.Conv2d_conv1                  [256, 64, 1, 1]   [1, 64, 128, 128]   \n",
      "12_layer1.1.BatchNorm2d_bn1                          [64]   [1, 64, 128, 128]   \n",
      "13_layer1.1.ReLU_relu                                   -   [1, 64, 128, 128]   \n",
      "14_layer1.1.Conv2d_conv2                   [64, 64, 3, 3]   [1, 64, 128, 128]   \n",
      "15_layer1.1.BatchNorm2d_bn2                          [64]   [1, 64, 128, 128]   \n",
      "16_layer1.1.ReLU_relu                                   -   [1, 64, 128, 128]   \n",
      "17_layer1.1.Conv2d_conv3                  [64, 256, 1, 1]  [1, 256, 128, 128]   \n",
      "18_layer1.1.BatchNorm2d_bn3                         [256]  [1, 256, 128, 128]   \n",
      "19_layer1.1.ReLU_relu                                   -  [1, 256, 128, 128]   \n",
      "20_layer1.2.Conv2d_conv1                  [256, 64, 1, 1]   [1, 64, 128, 128]   \n",
      "21_layer1.2.BatchNorm2d_bn1                          [64]   [1, 64, 128, 128]   \n",
      "22_layer1.2.ReLU_relu                                   -   [1, 64, 128, 128]   \n",
      "23_layer1.2.Conv2d_conv2                   [64, 64, 3, 3]   [1, 64, 128, 128]   \n",
      "24_layer1.2.BatchNorm2d_bn2                          [64]   [1, 64, 128, 128]   \n",
      "25_layer1.2.ReLU_relu                                   -   [1, 64, 128, 128]   \n",
      "26_layer1.2.Conv2d_conv3                  [64, 256, 1, 1]  [1, 256, 128, 128]   \n",
      "27_layer1.2.BatchNorm2d_bn3                         [256]  [1, 256, 128, 128]   \n",
      "28_layer1.2.ReLU_relu                                   -  [1, 256, 128, 128]   \n",
      "29_layer2.0.Conv2d_conv1                 [256, 128, 1, 1]  [1, 128, 128, 128]   \n",
      "30_layer2.0.BatchNorm2d_bn1                         [128]  [1, 128, 128, 128]   \n",
      "31_layer2.0.ReLU_relu                                   -  [1, 128, 128, 128]   \n",
      "32_layer2.0.Conv2d_conv2                 [128, 128, 3, 3]    [1, 128, 64, 64]   \n",
      "33_layer2.0.BatchNorm2d_bn2                         [128]    [1, 128, 64, 64]   \n",
      "34_layer2.0.ReLU_relu                                   -    [1, 128, 64, 64]   \n",
      "35_layer2.0.Conv2d_conv3                 [128, 512, 1, 1]    [1, 512, 64, 64]   \n",
      "36_layer2.0.BatchNorm2d_bn3                         [512]    [1, 512, 64, 64]   \n",
      "37_layer2.0.downsample.Conv2d_0          [256, 512, 1, 1]    [1, 512, 64, 64]   \n",
      "38_layer2.0.downsample.BatchNorm2d_1                [512]    [1, 512, 64, 64]   \n",
      "39_layer2.0.ReLU_relu                                   -    [1, 512, 64, 64]   \n",
      "40_layer2.1.Conv2d_conv1                 [512, 128, 1, 1]    [1, 128, 64, 64]   \n",
      "41_layer2.1.BatchNorm2d_bn1                         [128]    [1, 128, 64, 64]   \n",
      "42_layer2.1.ReLU_relu                                   -    [1, 128, 64, 64]   \n",
      "43_layer2.1.Conv2d_conv2                 [128, 128, 3, 3]    [1, 128, 64, 64]   \n",
      "44_layer2.1.BatchNorm2d_bn2                         [128]    [1, 128, 64, 64]   \n",
      "45_layer2.1.ReLU_relu                                   -    [1, 128, 64, 64]   \n",
      "46_layer2.1.Conv2d_conv3                 [128, 512, 1, 1]    [1, 512, 64, 64]   \n",
      "47_layer2.1.BatchNorm2d_bn3                         [512]    [1, 512, 64, 64]   \n",
      "48_layer2.1.ReLU_relu                                   -    [1, 512, 64, 64]   \n",
      "49_layer2.2.Conv2d_conv1                 [512, 128, 1, 1]    [1, 128, 64, 64]   \n",
      "50_layer2.2.BatchNorm2d_bn1                         [128]    [1, 128, 64, 64]   \n",
      "51_layer2.2.ReLU_relu                                   -    [1, 128, 64, 64]   \n",
      "52_layer2.2.Conv2d_conv2                 [128, 128, 3, 3]    [1, 128, 64, 64]   \n",
      "53_layer2.2.BatchNorm2d_bn2                         [128]    [1, 128, 64, 64]   \n",
      "54_layer2.2.ReLU_relu                                   -    [1, 128, 64, 64]   \n",
      "55_layer2.2.Conv2d_conv3                 [128, 512, 1, 1]    [1, 512, 64, 64]   \n",
      "56_layer2.2.BatchNorm2d_bn3                         [512]    [1, 512, 64, 64]   \n",
      "57_layer2.2.ReLU_relu                                   -    [1, 512, 64, 64]   \n",
      "58_layer2.3.Conv2d_conv1                 [512, 128, 1, 1]    [1, 128, 64, 64]   \n",
      "59_layer2.3.BatchNorm2d_bn1                         [128]    [1, 128, 64, 64]   \n",
      "60_layer2.3.ReLU_relu                                   -    [1, 128, 64, 64]   \n",
      "61_layer2.3.Conv2d_conv2                 [128, 128, 3, 3]    [1, 128, 64, 64]   \n",
      "62_layer2.3.BatchNorm2d_bn2                         [128]    [1, 128, 64, 64]   \n",
      "63_layer2.3.ReLU_relu                                   -    [1, 128, 64, 64]   \n",
      "64_layer2.3.Conv2d_conv3                 [128, 512, 1, 1]    [1, 512, 64, 64]   \n",
      "65_layer2.3.BatchNorm2d_bn3                         [512]    [1, 512, 64, 64]   \n",
      "66_layer2.3.ReLU_relu                                   -    [1, 512, 64, 64]   \n",
      "67_layer3.0.Conv2d_conv1                 [512, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "68_layer3.0.BatchNorm2d_bn1                         [256]    [1, 256, 64, 64]   \n",
      "69_layer3.0.ReLU_relu                                   -    [1, 256, 64, 64]   \n",
      "70_layer3.0.Conv2d_conv2                 [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "71_layer3.0.BatchNorm2d_bn2                         [256]    [1, 256, 64, 64]   \n",
      "72_layer3.0.ReLU_relu                                   -    [1, 256, 64, 64]   \n",
      "73_layer3.0.Conv2d_conv3                [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "74_layer3.0.BatchNorm2d_bn3                        [1024]   [1, 1024, 64, 64]   \n",
      "75_layer3.0.downsample.Conv2d_0         [512, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "76_layer3.0.downsample.BatchNorm2d_1               [1024]   [1, 1024, 64, 64]   \n",
      "77_layer3.0.ReLU_relu                                   -   [1, 1024, 64, 64]   \n",
      "78_layer3.1.Conv2d_conv1                [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "79_layer3.1.BatchNorm2d_bn1                         [256]    [1, 256, 64, 64]   \n",
      "80_layer3.1.ReLU_relu                                   -    [1, 256, 64, 64]   \n",
      "81_layer3.1.Conv2d_conv2                 [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "82_layer3.1.BatchNorm2d_bn2                         [256]    [1, 256, 64, 64]   \n",
      "83_layer3.1.ReLU_relu                                   -    [1, 256, 64, 64]   \n",
      "84_layer3.1.Conv2d_conv3                [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "85_layer3.1.BatchNorm2d_bn3                        [1024]   [1, 1024, 64, 64]   \n",
      "86_layer3.1.ReLU_relu                                   -   [1, 1024, 64, 64]   \n",
      "87_layer3.2.Conv2d_conv1                [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "88_layer3.2.BatchNorm2d_bn1                         [256]    [1, 256, 64, 64]   \n",
      "89_layer3.2.ReLU_relu                                   -    [1, 256, 64, 64]   \n",
      "90_layer3.2.Conv2d_conv2                 [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "91_layer3.2.BatchNorm2d_bn2                         [256]    [1, 256, 64, 64]   \n",
      "92_layer3.2.ReLU_relu                                   -    [1, 256, 64, 64]   \n",
      "93_layer3.2.Conv2d_conv3                [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "94_layer3.2.BatchNorm2d_bn3                        [1024]   [1, 1024, 64, 64]   \n",
      "95_layer3.2.ReLU_relu                                   -   [1, 1024, 64, 64]   \n",
      "96_layer3.3.Conv2d_conv1                [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "97_layer3.3.BatchNorm2d_bn1                         [256]    [1, 256, 64, 64]   \n",
      "98_layer3.3.ReLU_relu                                   -    [1, 256, 64, 64]   \n",
      "99_layer3.3.Conv2d_conv2                 [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "100_layer3.3.BatchNorm2d_bn2                        [256]    [1, 256, 64, 64]   \n",
      "101_layer3.3.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "102_layer3.3.Conv2d_conv3               [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "103_layer3.3.BatchNorm2d_bn3                       [1024]   [1, 1024, 64, 64]   \n",
      "104_layer3.3.ReLU_relu                                  -   [1, 1024, 64, 64]   \n",
      "105_layer3.4.Conv2d_conv1               [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "106_layer3.4.BatchNorm2d_bn1                        [256]    [1, 256, 64, 64]   \n",
      "107_layer3.4.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "108_layer3.4.Conv2d_conv2                [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "109_layer3.4.BatchNorm2d_bn2                        [256]    [1, 256, 64, 64]   \n",
      "110_layer3.4.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "111_layer3.4.Conv2d_conv3               [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "112_layer3.4.BatchNorm2d_bn3                       [1024]   [1, 1024, 64, 64]   \n",
      "113_layer3.4.ReLU_relu                                  -   [1, 1024, 64, 64]   \n",
      "114_layer3.5.Conv2d_conv1               [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "115_layer3.5.BatchNorm2d_bn1                        [256]    [1, 256, 64, 64]   \n",
      "116_layer3.5.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "117_layer3.5.Conv2d_conv2                [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "118_layer3.5.BatchNorm2d_bn2                        [256]    [1, 256, 64, 64]   \n",
      "119_layer3.5.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "120_layer3.5.Conv2d_conv3               [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "121_layer3.5.BatchNorm2d_bn3                       [1024]   [1, 1024, 64, 64]   \n",
      "122_layer3.5.ReLU_relu                                  -   [1, 1024, 64, 64]   \n",
      "123_layer3.6.Conv2d_conv1               [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "124_layer3.6.BatchNorm2d_bn1                        [256]    [1, 256, 64, 64]   \n",
      "125_layer3.6.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "126_layer3.6.Conv2d_conv2                [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "127_layer3.6.BatchNorm2d_bn2                        [256]    [1, 256, 64, 64]   \n",
      "128_layer3.6.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "129_layer3.6.Conv2d_conv3               [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "130_layer3.6.BatchNorm2d_bn3                       [1024]   [1, 1024, 64, 64]   \n",
      "131_layer3.6.ReLU_relu                                  -   [1, 1024, 64, 64]   \n",
      "132_layer3.7.Conv2d_conv1               [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "133_layer3.7.BatchNorm2d_bn1                        [256]    [1, 256, 64, 64]   \n",
      "134_layer3.7.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "135_layer3.7.Conv2d_conv2                [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "136_layer3.7.BatchNorm2d_bn2                        [256]    [1, 256, 64, 64]   \n",
      "137_layer3.7.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "138_layer3.7.Conv2d_conv3               [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "139_layer3.7.BatchNorm2d_bn3                       [1024]   [1, 1024, 64, 64]   \n",
      "140_layer3.7.ReLU_relu                                  -   [1, 1024, 64, 64]   \n",
      "141_layer3.8.Conv2d_conv1               [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "142_layer3.8.BatchNorm2d_bn1                        [256]    [1, 256, 64, 64]   \n",
      "143_layer3.8.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "144_layer3.8.Conv2d_conv2                [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "145_layer3.8.BatchNorm2d_bn2                        [256]    [1, 256, 64, 64]   \n",
      "146_layer3.8.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "147_layer3.8.Conv2d_conv3               [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "148_layer3.8.BatchNorm2d_bn3                       [1024]   [1, 1024, 64, 64]   \n",
      "149_layer3.8.ReLU_relu                                  -   [1, 1024, 64, 64]   \n",
      "150_layer3.9.Conv2d_conv1               [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "151_layer3.9.BatchNorm2d_bn1                        [256]    [1, 256, 64, 64]   \n",
      "152_layer3.9.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "153_layer3.9.Conv2d_conv2                [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "154_layer3.9.BatchNorm2d_bn2                        [256]    [1, 256, 64, 64]   \n",
      "155_layer3.9.ReLU_relu                                  -    [1, 256, 64, 64]   \n",
      "156_layer3.9.Conv2d_conv3               [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "157_layer3.9.BatchNorm2d_bn3                       [1024]   [1, 1024, 64, 64]   \n",
      "158_layer3.9.ReLU_relu                                  -   [1, 1024, 64, 64]   \n",
      "159_layer3.10.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "160_layer3.10.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "161_layer3.10.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "162_layer3.10.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "163_layer3.10.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "164_layer3.10.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "165_layer3.10.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "166_layer3.10.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "167_layer3.10.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "168_layer3.11.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "169_layer3.11.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "170_layer3.11.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "171_layer3.11.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "172_layer3.11.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "173_layer3.11.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "174_layer3.11.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "175_layer3.11.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "176_layer3.11.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "177_layer3.12.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "178_layer3.12.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "179_layer3.12.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "180_layer3.12.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "181_layer3.12.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "182_layer3.12.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "183_layer3.12.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "184_layer3.12.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "185_layer3.12.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "186_layer3.13.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "187_layer3.13.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "188_layer3.13.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "189_layer3.13.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "190_layer3.13.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "191_layer3.13.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "192_layer3.13.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "193_layer3.13.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "194_layer3.13.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "195_layer3.14.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "196_layer3.14.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "197_layer3.14.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "198_layer3.14.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "199_layer3.14.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "200_layer3.14.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "201_layer3.14.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "202_layer3.14.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "203_layer3.14.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "204_layer3.15.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "205_layer3.15.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "206_layer3.15.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "207_layer3.15.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "208_layer3.15.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "209_layer3.15.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "210_layer3.15.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "211_layer3.15.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "212_layer3.15.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "213_layer3.16.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "214_layer3.16.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "215_layer3.16.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "216_layer3.16.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "217_layer3.16.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "218_layer3.16.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "219_layer3.16.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "220_layer3.16.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "221_layer3.16.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "222_layer3.17.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "223_layer3.17.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "224_layer3.17.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "225_layer3.17.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "226_layer3.17.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "227_layer3.17.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "228_layer3.17.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "229_layer3.17.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "230_layer3.17.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "231_layer3.18.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "232_layer3.18.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "233_layer3.18.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "234_layer3.18.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "235_layer3.18.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "236_layer3.18.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "237_layer3.18.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "238_layer3.18.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "239_layer3.18.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "240_layer3.19.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "241_layer3.19.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "242_layer3.19.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "243_layer3.19.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "244_layer3.19.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "245_layer3.19.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "246_layer3.19.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "247_layer3.19.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "248_layer3.19.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "249_layer3.20.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "250_layer3.20.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "251_layer3.20.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "252_layer3.20.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "253_layer3.20.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "254_layer3.20.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "255_layer3.20.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "256_layer3.20.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "257_layer3.20.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "258_layer3.21.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "259_layer3.21.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "260_layer3.21.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "261_layer3.21.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "262_layer3.21.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "263_layer3.21.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "264_layer3.21.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "265_layer3.21.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "266_layer3.21.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "267_layer3.22.Conv2d_conv1              [1024, 256, 1, 1]    [1, 256, 64, 64]   \n",
      "268_layer3.22.BatchNorm2d_bn1                       [256]    [1, 256, 64, 64]   \n",
      "269_layer3.22.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "270_layer3.22.Conv2d_conv2               [256, 256, 3, 3]    [1, 256, 64, 64]   \n",
      "271_layer3.22.BatchNorm2d_bn2                       [256]    [1, 256, 64, 64]   \n",
      "272_layer3.22.ReLU_relu                                 -    [1, 256, 64, 64]   \n",
      "273_layer3.22.Conv2d_conv3              [256, 1024, 1, 1]   [1, 1024, 64, 64]   \n",
      "274_layer3.22.BatchNorm2d_bn3                      [1024]   [1, 1024, 64, 64]   \n",
      "275_layer3.22.ReLU_relu                                 -   [1, 1024, 64, 64]   \n",
      "276_layer4.0.Conv2d_conv1               [1024, 512, 1, 1]    [1, 512, 64, 64]   \n",
      "277_layer4.0.BatchNorm2d_bn1                        [512]    [1, 512, 64, 64]   \n",
      "278_layer4.0.ReLU_relu                                  -    [1, 512, 64, 64]   \n",
      "279_layer4.0.Conv2d_conv2                [512, 512, 3, 3]    [1, 512, 64, 64]   \n",
      "280_layer4.0.BatchNorm2d_bn2                        [512]    [1, 512, 64, 64]   \n",
      "281_layer4.0.ReLU_relu                                  -    [1, 512, 64, 64]   \n",
      "282_layer4.0.Conv2d_conv3               [512, 2048, 1, 1]   [1, 2048, 64, 64]   \n",
      "283_layer4.0.BatchNorm2d_bn3                       [2048]   [1, 2048, 64, 64]   \n",
      "284_layer4.0.downsample.Conv2d_0       [1024, 2048, 1, 1]   [1, 2048, 64, 64]   \n",
      "285_layer4.0.downsample.BatchNorm2d_1              [2048]   [1, 2048, 64, 64]   \n",
      "286_layer4.0.ReLU_relu                                  -   [1, 2048, 64, 64]   \n",
      "287_layer4.1.Conv2d_conv1               [2048, 512, 1, 1]    [1, 512, 64, 64]   \n",
      "288_layer4.1.BatchNorm2d_bn1                        [512]    [1, 512, 64, 64]   \n",
      "289_layer4.1.ReLU_relu                                  -    [1, 512, 64, 64]   \n",
      "290_layer4.1.Conv2d_conv2                [512, 512, 3, 3]    [1, 512, 64, 64]   \n",
      "291_layer4.1.BatchNorm2d_bn2                        [512]    [1, 512, 64, 64]   \n",
      "292_layer4.1.ReLU_relu                                  -    [1, 512, 64, 64]   \n",
      "293_layer4.1.Conv2d_conv3               [512, 2048, 1, 1]   [1, 2048, 64, 64]   \n",
      "294_layer4.1.BatchNorm2d_bn3                       [2048]   [1, 2048, 64, 64]   \n",
      "295_layer4.1.ReLU_relu                                  -   [1, 2048, 64, 64]   \n",
      "296_layer4.2.Conv2d_conv1               [2048, 512, 1, 1]    [1, 512, 64, 64]   \n",
      "297_layer4.2.BatchNorm2d_bn1                        [512]    [1, 512, 64, 64]   \n",
      "298_layer4.2.ReLU_relu                                  -    [1, 512, 64, 64]   \n",
      "299_layer4.2.Conv2d_conv2                [512, 512, 3, 3]    [1, 512, 64, 64]   \n",
      "300_layer4.2.BatchNorm2d_bn2                        [512]    [1, 512, 64, 64]   \n",
      "301_layer4.2.ReLU_relu                                  -    [1, 512, 64, 64]   \n",
      "302_layer4.2.Conv2d_conv3               [512, 2048, 1, 1]   [1, 2048, 64, 64]   \n",
      "303_layer4.2.BatchNorm2d_bn3                       [2048]   [1, 2048, 64, 64]   \n",
      "304_layer4.2.ReLU_relu                                  -   [1, 2048, 64, 64]   \n",
      "\n",
      "                                          Params     Mult-Adds  \n",
      "Layer                                                           \n",
      "0_layer1.0.Conv2d_conv1                   4.096k    67.108864M  \n",
      "1_layer1.0.BatchNorm2d_bn1                 128.0          64.0  \n",
      "2_layer1.0.ReLU_relu                           -             -  \n",
      "3_layer1.0.Conv2d_conv2                  36.864k   603.979776M  \n",
      "4_layer1.0.BatchNorm2d_bn2                 128.0          64.0  \n",
      "5_layer1.0.ReLU_relu                           -             -  \n",
      "6_layer1.0.Conv2d_conv3                  16.384k   268.435456M  \n",
      "7_layer1.0.BatchNorm2d_bn3                 512.0         256.0  \n",
      "8_layer1.0.downsample.Conv2d_0           16.384k   268.435456M  \n",
      "9_layer1.0.downsample.BatchNorm2d_1        512.0         256.0  \n",
      "10_layer1.0.ReLU_relu                          -             -  \n",
      "11_layer1.1.Conv2d_conv1                 16.384k   268.435456M  \n",
      "12_layer1.1.BatchNorm2d_bn1                128.0          64.0  \n",
      "13_layer1.1.ReLU_relu                          -             -  \n",
      "14_layer1.1.Conv2d_conv2                 36.864k   603.979776M  \n",
      "15_layer1.1.BatchNorm2d_bn2                128.0          64.0  \n",
      "16_layer1.1.ReLU_relu                          -             -  \n",
      "17_layer1.1.Conv2d_conv3                 16.384k   268.435456M  \n",
      "18_layer1.1.BatchNorm2d_bn3                512.0         256.0  \n",
      "19_layer1.1.ReLU_relu                          -             -  \n",
      "20_layer1.2.Conv2d_conv1                 16.384k   268.435456M  \n",
      "21_layer1.2.BatchNorm2d_bn1                128.0          64.0  \n",
      "22_layer1.2.ReLU_relu                          -             -  \n",
      "23_layer1.2.Conv2d_conv2                 36.864k   603.979776M  \n",
      "24_layer1.2.BatchNorm2d_bn2                128.0          64.0  \n",
      "25_layer1.2.ReLU_relu                          -             -  \n",
      "26_layer1.2.Conv2d_conv3                 16.384k   268.435456M  \n",
      "27_layer1.2.BatchNorm2d_bn3                512.0         256.0  \n",
      "28_layer1.2.ReLU_relu                          -             -  \n",
      "29_layer2.0.Conv2d_conv1                 32.768k   536.870912M  \n",
      "30_layer2.0.BatchNorm2d_bn1                256.0         128.0  \n",
      "31_layer2.0.ReLU_relu                          -             -  \n",
      "32_layer2.0.Conv2d_conv2                147.456k   603.979776M  \n",
      "33_layer2.0.BatchNorm2d_bn2                256.0         128.0  \n",
      "34_layer2.0.ReLU_relu                          -             -  \n",
      "35_layer2.0.Conv2d_conv3                 65.536k   268.435456M  \n",
      "36_layer2.0.BatchNorm2d_bn3               1.024k         512.0  \n",
      "37_layer2.0.downsample.Conv2d_0         131.072k   536.870912M  \n",
      "38_layer2.0.downsample.BatchNorm2d_1      1.024k         512.0  \n",
      "39_layer2.0.ReLU_relu                          -             -  \n",
      "40_layer2.1.Conv2d_conv1                 65.536k   268.435456M  \n",
      "41_layer2.1.BatchNorm2d_bn1                256.0         128.0  \n",
      "42_layer2.1.ReLU_relu                          -             -  \n",
      "43_layer2.1.Conv2d_conv2                147.456k   603.979776M  \n",
      "44_layer2.1.BatchNorm2d_bn2                256.0         128.0  \n",
      "45_layer2.1.ReLU_relu                          -             -  \n",
      "46_layer2.1.Conv2d_conv3                 65.536k   268.435456M  \n",
      "47_layer2.1.BatchNorm2d_bn3               1.024k         512.0  \n",
      "48_layer2.1.ReLU_relu                          -             -  \n",
      "49_layer2.2.Conv2d_conv1                 65.536k   268.435456M  \n",
      "50_layer2.2.BatchNorm2d_bn1                256.0         128.0  \n",
      "51_layer2.2.ReLU_relu                          -             -  \n",
      "52_layer2.2.Conv2d_conv2                147.456k   603.979776M  \n",
      "53_layer2.2.BatchNorm2d_bn2                256.0         128.0  \n",
      "54_layer2.2.ReLU_relu                          -             -  \n",
      "55_layer2.2.Conv2d_conv3                 65.536k   268.435456M  \n",
      "56_layer2.2.BatchNorm2d_bn3               1.024k         512.0  \n",
      "57_layer2.2.ReLU_relu                          -             -  \n",
      "58_layer2.3.Conv2d_conv1                 65.536k   268.435456M  \n",
      "59_layer2.3.BatchNorm2d_bn1                256.0         128.0  \n",
      "60_layer2.3.ReLU_relu                          -             -  \n",
      "61_layer2.3.Conv2d_conv2                147.456k   603.979776M  \n",
      "62_layer2.3.BatchNorm2d_bn2                256.0         128.0  \n",
      "63_layer2.3.ReLU_relu                          -             -  \n",
      "64_layer2.3.Conv2d_conv3                 65.536k   268.435456M  \n",
      "65_layer2.3.BatchNorm2d_bn3               1.024k         512.0  \n",
      "66_layer2.3.ReLU_relu                          -             -  \n",
      "67_layer3.0.Conv2d_conv1                131.072k   536.870912M  \n",
      "68_layer3.0.BatchNorm2d_bn1                512.0         256.0  \n",
      "69_layer3.0.ReLU_relu                          -             -  \n",
      "70_layer3.0.Conv2d_conv2                589.824k  2.415919104G  \n",
      "71_layer3.0.BatchNorm2d_bn2                512.0         256.0  \n",
      "72_layer3.0.ReLU_relu                          -             -  \n",
      "73_layer3.0.Conv2d_conv3                262.144k  1.073741824G  \n",
      "74_layer3.0.BatchNorm2d_bn3               2.048k        1.024k  \n",
      "75_layer3.0.downsample.Conv2d_0         524.288k  2.147483648G  \n",
      "76_layer3.0.downsample.BatchNorm2d_1      2.048k        1.024k  \n",
      "77_layer3.0.ReLU_relu                          -             -  \n",
      "78_layer3.1.Conv2d_conv1                262.144k  1.073741824G  \n",
      "79_layer3.1.BatchNorm2d_bn1                512.0         256.0  \n",
      "80_layer3.1.ReLU_relu                          -             -  \n",
      "81_layer3.1.Conv2d_conv2                589.824k  2.415919104G  \n",
      "82_layer3.1.BatchNorm2d_bn2                512.0         256.0  \n",
      "83_layer3.1.ReLU_relu                          -             -  \n",
      "84_layer3.1.Conv2d_conv3                262.144k  1.073741824G  \n",
      "85_layer3.1.BatchNorm2d_bn3               2.048k        1.024k  \n",
      "86_layer3.1.ReLU_relu                          -             -  \n",
      "87_layer3.2.Conv2d_conv1                262.144k  1.073741824G  \n",
      "88_layer3.2.BatchNorm2d_bn1                512.0         256.0  \n",
      "89_layer3.2.ReLU_relu                          -             -  \n",
      "90_layer3.2.Conv2d_conv2                589.824k  2.415919104G  \n",
      "91_layer3.2.BatchNorm2d_bn2                512.0         256.0  \n",
      "92_layer3.2.ReLU_relu                          -             -  \n",
      "93_layer3.2.Conv2d_conv3                262.144k  1.073741824G  \n",
      "94_layer3.2.BatchNorm2d_bn3               2.048k        1.024k  \n",
      "95_layer3.2.ReLU_relu                          -             -  \n",
      "96_layer3.3.Conv2d_conv1                262.144k  1.073741824G  \n",
      "97_layer3.3.BatchNorm2d_bn1                512.0         256.0  \n",
      "98_layer3.3.ReLU_relu                          -             -  \n",
      "99_layer3.3.Conv2d_conv2                589.824k  2.415919104G  \n",
      "100_layer3.3.BatchNorm2d_bn2               512.0         256.0  \n",
      "101_layer3.3.ReLU_relu                         -             -  \n",
      "102_layer3.3.Conv2d_conv3               262.144k  1.073741824G  \n",
      "103_layer3.3.BatchNorm2d_bn3              2.048k        1.024k  \n",
      "104_layer3.3.ReLU_relu                         -             -  \n",
      "105_layer3.4.Conv2d_conv1               262.144k  1.073741824G  \n",
      "106_layer3.4.BatchNorm2d_bn1               512.0         256.0  \n",
      "107_layer3.4.ReLU_relu                         -             -  \n",
      "108_layer3.4.Conv2d_conv2               589.824k  2.415919104G  \n",
      "109_layer3.4.BatchNorm2d_bn2               512.0         256.0  \n",
      "110_layer3.4.ReLU_relu                         -             -  \n",
      "111_layer3.4.Conv2d_conv3               262.144k  1.073741824G  \n",
      "112_layer3.4.BatchNorm2d_bn3              2.048k        1.024k  \n",
      "113_layer3.4.ReLU_relu                         -             -  \n",
      "114_layer3.5.Conv2d_conv1               262.144k  1.073741824G  \n",
      "115_layer3.5.BatchNorm2d_bn1               512.0         256.0  \n",
      "116_layer3.5.ReLU_relu                         -             -  \n",
      "117_layer3.5.Conv2d_conv2               589.824k  2.415919104G  \n",
      "118_layer3.5.BatchNorm2d_bn2               512.0         256.0  \n",
      "119_layer3.5.ReLU_relu                         -             -  \n",
      "120_layer3.5.Conv2d_conv3               262.144k  1.073741824G  \n",
      "121_layer3.5.BatchNorm2d_bn3              2.048k        1.024k  \n",
      "122_layer3.5.ReLU_relu                         -             -  \n",
      "123_layer3.6.Conv2d_conv1               262.144k  1.073741824G  \n",
      "124_layer3.6.BatchNorm2d_bn1               512.0         256.0  \n",
      "125_layer3.6.ReLU_relu                         -             -  \n",
      "126_layer3.6.Conv2d_conv2               589.824k  2.415919104G  \n",
      "127_layer3.6.BatchNorm2d_bn2               512.0         256.0  \n",
      "128_layer3.6.ReLU_relu                         -             -  \n",
      "129_layer3.6.Conv2d_conv3               262.144k  1.073741824G  \n",
      "130_layer3.6.BatchNorm2d_bn3              2.048k        1.024k  \n",
      "131_layer3.6.ReLU_relu                         -             -  \n",
      "132_layer3.7.Conv2d_conv1               262.144k  1.073741824G  \n",
      "133_layer3.7.BatchNorm2d_bn1               512.0         256.0  \n",
      "134_layer3.7.ReLU_relu                         -             -  \n",
      "135_layer3.7.Conv2d_conv2               589.824k  2.415919104G  \n",
      "136_layer3.7.BatchNorm2d_bn2               512.0         256.0  \n",
      "137_layer3.7.ReLU_relu                         -             -  \n",
      "138_layer3.7.Conv2d_conv3               262.144k  1.073741824G  \n",
      "139_layer3.7.BatchNorm2d_bn3              2.048k        1.024k  \n",
      "140_layer3.7.ReLU_relu                         -             -  \n",
      "141_layer3.8.Conv2d_conv1               262.144k  1.073741824G  \n",
      "142_layer3.8.BatchNorm2d_bn1               512.0         256.0  \n",
      "143_layer3.8.ReLU_relu                         -             -  \n",
      "144_layer3.8.Conv2d_conv2               589.824k  2.415919104G  \n",
      "145_layer3.8.BatchNorm2d_bn2               512.0         256.0  \n",
      "146_layer3.8.ReLU_relu                         -             -  \n",
      "147_layer3.8.Conv2d_conv3               262.144k  1.073741824G  \n",
      "148_layer3.8.BatchNorm2d_bn3              2.048k        1.024k  \n",
      "149_layer3.8.ReLU_relu                         -             -  \n",
      "150_layer3.9.Conv2d_conv1               262.144k  1.073741824G  \n",
      "151_layer3.9.BatchNorm2d_bn1               512.0         256.0  \n",
      "152_layer3.9.ReLU_relu                         -             -  \n",
      "153_layer3.9.Conv2d_conv2               589.824k  2.415919104G  \n",
      "154_layer3.9.BatchNorm2d_bn2               512.0         256.0  \n",
      "155_layer3.9.ReLU_relu                         -             -  \n",
      "156_layer3.9.Conv2d_conv3               262.144k  1.073741824G  \n",
      "157_layer3.9.BatchNorm2d_bn3              2.048k        1.024k  \n",
      "158_layer3.9.ReLU_relu                         -             -  \n",
      "159_layer3.10.Conv2d_conv1              262.144k  1.073741824G  \n",
      "160_layer3.10.BatchNorm2d_bn1              512.0         256.0  \n",
      "161_layer3.10.ReLU_relu                        -             -  \n",
      "162_layer3.10.Conv2d_conv2              589.824k  2.415919104G  \n",
      "163_layer3.10.BatchNorm2d_bn2              512.0         256.0  \n",
      "164_layer3.10.ReLU_relu                        -             -  \n",
      "165_layer3.10.Conv2d_conv3              262.144k  1.073741824G  \n",
      "166_layer3.10.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "167_layer3.10.ReLU_relu                        -             -  \n",
      "168_layer3.11.Conv2d_conv1              262.144k  1.073741824G  \n",
      "169_layer3.11.BatchNorm2d_bn1              512.0         256.0  \n",
      "170_layer3.11.ReLU_relu                        -             -  \n",
      "171_layer3.11.Conv2d_conv2              589.824k  2.415919104G  \n",
      "172_layer3.11.BatchNorm2d_bn2              512.0         256.0  \n",
      "173_layer3.11.ReLU_relu                        -             -  \n",
      "174_layer3.11.Conv2d_conv3              262.144k  1.073741824G  \n",
      "175_layer3.11.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "176_layer3.11.ReLU_relu                        -             -  \n",
      "177_layer3.12.Conv2d_conv1              262.144k  1.073741824G  \n",
      "178_layer3.12.BatchNorm2d_bn1              512.0         256.0  \n",
      "179_layer3.12.ReLU_relu                        -             -  \n",
      "180_layer3.12.Conv2d_conv2              589.824k  2.415919104G  \n",
      "181_layer3.12.BatchNorm2d_bn2              512.0         256.0  \n",
      "182_layer3.12.ReLU_relu                        -             -  \n",
      "183_layer3.12.Conv2d_conv3              262.144k  1.073741824G  \n",
      "184_layer3.12.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "185_layer3.12.ReLU_relu                        -             -  \n",
      "186_layer3.13.Conv2d_conv1              262.144k  1.073741824G  \n",
      "187_layer3.13.BatchNorm2d_bn1              512.0         256.0  \n",
      "188_layer3.13.ReLU_relu                        -             -  \n",
      "189_layer3.13.Conv2d_conv2              589.824k  2.415919104G  \n",
      "190_layer3.13.BatchNorm2d_bn2              512.0         256.0  \n",
      "191_layer3.13.ReLU_relu                        -             -  \n",
      "192_layer3.13.Conv2d_conv3              262.144k  1.073741824G  \n",
      "193_layer3.13.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "194_layer3.13.ReLU_relu                        -             -  \n",
      "195_layer3.14.Conv2d_conv1              262.144k  1.073741824G  \n",
      "196_layer3.14.BatchNorm2d_bn1              512.0         256.0  \n",
      "197_layer3.14.ReLU_relu                        -             -  \n",
      "198_layer3.14.Conv2d_conv2              589.824k  2.415919104G  \n",
      "199_layer3.14.BatchNorm2d_bn2              512.0         256.0  \n",
      "200_layer3.14.ReLU_relu                        -             -  \n",
      "201_layer3.14.Conv2d_conv3              262.144k  1.073741824G  \n",
      "202_layer3.14.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "203_layer3.14.ReLU_relu                        -             -  \n",
      "204_layer3.15.Conv2d_conv1              262.144k  1.073741824G  \n",
      "205_layer3.15.BatchNorm2d_bn1              512.0         256.0  \n",
      "206_layer3.15.ReLU_relu                        -             -  \n",
      "207_layer3.15.Conv2d_conv2              589.824k  2.415919104G  \n",
      "208_layer3.15.BatchNorm2d_bn2              512.0         256.0  \n",
      "209_layer3.15.ReLU_relu                        -             -  \n",
      "210_layer3.15.Conv2d_conv3              262.144k  1.073741824G  \n",
      "211_layer3.15.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "212_layer3.15.ReLU_relu                        -             -  \n",
      "213_layer3.16.Conv2d_conv1              262.144k  1.073741824G  \n",
      "214_layer3.16.BatchNorm2d_bn1              512.0         256.0  \n",
      "215_layer3.16.ReLU_relu                        -             -  \n",
      "216_layer3.16.Conv2d_conv2              589.824k  2.415919104G  \n",
      "217_layer3.16.BatchNorm2d_bn2              512.0         256.0  \n",
      "218_layer3.16.ReLU_relu                        -             -  \n",
      "219_layer3.16.Conv2d_conv3              262.144k  1.073741824G  \n",
      "220_layer3.16.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "221_layer3.16.ReLU_relu                        -             -  \n",
      "222_layer3.17.Conv2d_conv1              262.144k  1.073741824G  \n",
      "223_layer3.17.BatchNorm2d_bn1              512.0         256.0  \n",
      "224_layer3.17.ReLU_relu                        -             -  \n",
      "225_layer3.17.Conv2d_conv2              589.824k  2.415919104G  \n",
      "226_layer3.17.BatchNorm2d_bn2              512.0         256.0  \n",
      "227_layer3.17.ReLU_relu                        -             -  \n",
      "228_layer3.17.Conv2d_conv3              262.144k  1.073741824G  \n",
      "229_layer3.17.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "230_layer3.17.ReLU_relu                        -             -  \n",
      "231_layer3.18.Conv2d_conv1              262.144k  1.073741824G  \n",
      "232_layer3.18.BatchNorm2d_bn1              512.0         256.0  \n",
      "233_layer3.18.ReLU_relu                        -             -  \n",
      "234_layer3.18.Conv2d_conv2              589.824k  2.415919104G  \n",
      "235_layer3.18.BatchNorm2d_bn2              512.0         256.0  \n",
      "236_layer3.18.ReLU_relu                        -             -  \n",
      "237_layer3.18.Conv2d_conv3              262.144k  1.073741824G  \n",
      "238_layer3.18.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "239_layer3.18.ReLU_relu                        -             -  \n",
      "240_layer3.19.Conv2d_conv1              262.144k  1.073741824G  \n",
      "241_layer3.19.BatchNorm2d_bn1              512.0         256.0  \n",
      "242_layer3.19.ReLU_relu                        -             -  \n",
      "243_layer3.19.Conv2d_conv2              589.824k  2.415919104G  \n",
      "244_layer3.19.BatchNorm2d_bn2              512.0         256.0  \n",
      "245_layer3.19.ReLU_relu                        -             -  \n",
      "246_layer3.19.Conv2d_conv3              262.144k  1.073741824G  \n",
      "247_layer3.19.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "248_layer3.19.ReLU_relu                        -             -  \n",
      "249_layer3.20.Conv2d_conv1              262.144k  1.073741824G  \n",
      "250_layer3.20.BatchNorm2d_bn1              512.0         256.0  \n",
      "251_layer3.20.ReLU_relu                        -             -  \n",
      "252_layer3.20.Conv2d_conv2              589.824k  2.415919104G  \n",
      "253_layer3.20.BatchNorm2d_bn2              512.0         256.0  \n",
      "254_layer3.20.ReLU_relu                        -             -  \n",
      "255_layer3.20.Conv2d_conv3              262.144k  1.073741824G  \n",
      "256_layer3.20.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "257_layer3.20.ReLU_relu                        -             -  \n",
      "258_layer3.21.Conv2d_conv1              262.144k  1.073741824G  \n",
      "259_layer3.21.BatchNorm2d_bn1              512.0         256.0  \n",
      "260_layer3.21.ReLU_relu                        -             -  \n",
      "261_layer3.21.Conv2d_conv2              589.824k  2.415919104G  \n",
      "262_layer3.21.BatchNorm2d_bn2              512.0         256.0  \n",
      "263_layer3.21.ReLU_relu                        -             -  \n",
      "264_layer3.21.Conv2d_conv3              262.144k  1.073741824G  \n",
      "265_layer3.21.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "266_layer3.21.ReLU_relu                        -             -  \n",
      "267_layer3.22.Conv2d_conv1              262.144k  1.073741824G  \n",
      "268_layer3.22.BatchNorm2d_bn1              512.0         256.0  \n",
      "269_layer3.22.ReLU_relu                        -             -  \n",
      "270_layer3.22.Conv2d_conv2              589.824k  2.415919104G  \n",
      "271_layer3.22.BatchNorm2d_bn2              512.0         256.0  \n",
      "272_layer3.22.ReLU_relu                        -             -  \n",
      "273_layer3.22.Conv2d_conv3              262.144k  1.073741824G  \n",
      "274_layer3.22.BatchNorm2d_bn3             2.048k        1.024k  \n",
      "275_layer3.22.ReLU_relu                        -             -  \n",
      "276_layer4.0.Conv2d_conv1               524.288k  2.147483648G  \n",
      "277_layer4.0.BatchNorm2d_bn1              1.024k         512.0  \n",
      "278_layer4.0.ReLU_relu                         -             -  \n",
      "279_layer4.0.Conv2d_conv2              2.359296M  9.663676416G  \n",
      "280_layer4.0.BatchNorm2d_bn2              1.024k         512.0  \n",
      "281_layer4.0.ReLU_relu                         -             -  \n",
      "282_layer4.0.Conv2d_conv3              1.048576M  4.294967296G  \n",
      "283_layer4.0.BatchNorm2d_bn3              4.096k        2.048k  \n",
      "284_layer4.0.downsample.Conv2d_0       2.097152M  8.589934592G  \n",
      "285_layer4.0.downsample.BatchNorm2d_1     4.096k        2.048k  \n",
      "286_layer4.0.ReLU_relu                         -             -  \n",
      "287_layer4.1.Conv2d_conv1              1.048576M  4.294967296G  \n",
      "288_layer4.1.BatchNorm2d_bn1              1.024k         512.0  \n",
      "289_layer4.1.ReLU_relu                         -             -  \n",
      "290_layer4.1.Conv2d_conv2              2.359296M  9.663676416G  \n",
      "291_layer4.1.BatchNorm2d_bn2              1.024k         512.0  \n",
      "292_layer4.1.ReLU_relu                         -             -  \n",
      "293_layer4.1.Conv2d_conv3              1.048576M  4.294967296G  \n",
      "294_layer4.1.BatchNorm2d_bn3              4.096k        2.048k  \n",
      "295_layer4.1.ReLU_relu                         -             -  \n",
      "296_layer4.2.Conv2d_conv1              1.048576M  4.294967296G  \n",
      "297_layer4.2.BatchNorm2d_bn1              1.024k         512.0  \n",
      "298_layer4.2.ReLU_relu                         -             -  \n",
      "299_layer4.2.Conv2d_conv2              2.359296M  9.663676416G  \n",
      "300_layer4.2.BatchNorm2d_bn2              1.024k         512.0  \n",
      "301_layer4.2.ReLU_relu                         -             -  \n",
      "302_layer4.2.Conv2d_conv3              1.048576M  4.294967296G  \n",
      "303_layer4.2.BatchNorm2d_bn3              4.096k        2.048k  \n",
      "304_layer4.2.ReLU_relu                         -             -  \n",
      "------------------------------------------------------------------------------------------------------\n",
      "                              Totals\n",
      "Total params              42.490624M\n",
      "Trainable params          42.490624M\n",
      "Non-trainable params             0.0\n",
      "Mult-Adds             176.630582656G\n",
      "======================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_layer1.0.Conv2d_conv1</th>\n",
       "      <td>[64, 64, 1, 1]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>6.710886e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_layer1.0.BatchNorm2d_bn1</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_layer1.0.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_layer1.0.Conv2d_conv2</th>\n",
       "      <td>[64, 64, 3, 3]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>6.039798e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_layer1.0.BatchNorm2d_bn2</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[1, 64, 128, 128]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300_layer4.2.BatchNorm2d_bn2</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[1, 512, 64, 64]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>5.120000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301_layer4.2.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 512, 64, 64]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302_layer4.2.Conv2d_conv3</th>\n",
       "      <td>[512, 2048, 1, 1]</td>\n",
       "      <td>[1, 2048, 64, 64]</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>4.294967e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303_layer4.2.BatchNorm2d_bn3</th>\n",
       "      <td>[2048]</td>\n",
       "      <td>[1, 2048, 64, 64]</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>2.048000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304_layer4.2.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 2048, 64, 64]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Kernel Shape       Output Shape     Params  \\\n",
       "Layer                                                                           \n",
       "0_layer1.0.Conv2d_conv1          [64, 64, 1, 1]  [1, 64, 128, 128]     4096.0   \n",
       "1_layer1.0.BatchNorm2d_bn1                 [64]  [1, 64, 128, 128]      128.0   \n",
       "2_layer1.0.ReLU_relu                          -  [1, 64, 128, 128]        NaN   \n",
       "3_layer1.0.Conv2d_conv2          [64, 64, 3, 3]  [1, 64, 128, 128]    36864.0   \n",
       "4_layer1.0.BatchNorm2d_bn2                 [64]  [1, 64, 128, 128]      128.0   \n",
       "...                                         ...                ...        ...   \n",
       "300_layer4.2.BatchNorm2d_bn2              [512]   [1, 512, 64, 64]     1024.0   \n",
       "301_layer4.2.ReLU_relu                        -   [1, 512, 64, 64]        NaN   \n",
       "302_layer4.2.Conv2d_conv3     [512, 2048, 1, 1]  [1, 2048, 64, 64]  1048576.0   \n",
       "303_layer4.2.BatchNorm2d_bn3             [2048]  [1, 2048, 64, 64]     4096.0   \n",
       "304_layer4.2.ReLU_relu                        -  [1, 2048, 64, 64]        NaN   \n",
       "\n",
       "                                 Mult-Adds  \n",
       "Layer                                       \n",
       "0_layer1.0.Conv2d_conv1       6.710886e+07  \n",
       "1_layer1.0.BatchNorm2d_bn1    6.400000e+01  \n",
       "2_layer1.0.ReLU_relu                   NaN  \n",
       "3_layer1.0.Conv2d_conv2       6.039798e+08  \n",
       "4_layer1.0.BatchNorm2d_bn2    6.400000e+01  \n",
       "...                                    ...  \n",
       "300_layer4.2.BatchNorm2d_bn2  5.120000e+02  \n",
       "301_layer4.2.ReLU_relu                 NaN  \n",
       "302_layer4.2.Conv2d_conv3     4.294967e+09  \n",
       "303_layer4.2.BatchNorm2d_bn3  2.048000e+03  \n",
       "304_layer4.2.ReLU_relu                 NaN  \n",
       "\n",
       "[305 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,head_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
